{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import warnings\n",
    "warnings.simplefilter('default', ImportWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "zf = zipfile.ZipFile('Sentiment140.csv.zip')\n",
    "df = pd.read_csv(zf.open('Sentiment140.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting 20000 random rows to develop the analysis\n",
    "df = df.sample(n=20000)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012883900</td>\n",
       "      <td>Tue Jun 02 21:28:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>peterdarlington</td>\n",
       "      <td>@dubdotdash I don't have aircon  Lovely office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2052369572</td>\n",
       "      <td>Sat Jun 06 00:30:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Preetha_87</td>\n",
       "      <td>Yesterday wasn't a great day..my best friend's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1967982555</td>\n",
       "      <td>Fri May 29 20:33:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LMRB</td>\n",
       "      <td>@hma4983 It's the same house  We came back &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1967192097</td>\n",
       "      <td>Fri May 29 19:08:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gabeezy</td>\n",
       "      <td>@reginaislegit is the new david sides!!!  http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1970340485</td>\n",
       "      <td>Sat May 30 03:27:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SharpShooter67</td>\n",
       "      <td>Driva! On the road again...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  2012883900  Tue Jun 02 21:28:37 PDT 2009  NO_QUERY   \n",
       "1       0  2052369572  Sat Jun 06 00:30:08 PDT 2009  NO_QUERY   \n",
       "2       4  1967982555  Fri May 29 20:33:23 PDT 2009  NO_QUERY   \n",
       "3       4  1967192097  Fri May 29 19:08:12 PDT 2009  NO_QUERY   \n",
       "4       4  1970340485  Sat May 30 03:27:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  peterdarlington  @dubdotdash I don't have aircon  Lovely office...  \n",
       "1       Preetha_87  Yesterday wasn't a great day..my best friend's...  \n",
       "2             LMRB  @hma4983 It's the same house  We came back &am...  \n",
       "3          gabeezy  @reginaislegit is the new david sides!!!  http...  \n",
       "4   SharpShooter67                       Driva! On the road again...   "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file with the functions\n",
    "%run Challenge_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Textual Data for Sentiment Analysis\n",
    "def text_proc(x):\n",
    "    text = clean_up(x)\n",
    "    text = tokenize(text)\n",
    "    text = stem_and_lemmatize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creting the new column with the text processed\n",
    "df['text_processed'] = df['text'].apply(lambda x: text_proc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012883900</td>\n",
       "      <td>Tue Jun 02 21:28:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>peterdarlington</td>\n",
       "      <td>@dubdotdash I don't have aircon  Lovely office...</td>\n",
       "      <td>[dubdotdash, aircon, love, offic, love, view, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2052369572</td>\n",
       "      <td>Sat Jun 06 00:30:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Preetha_87</td>\n",
       "      <td>Yesterday wasn't a great day..my best friend's...</td>\n",
       "      <td>[yesterday, great, day, best, friend, parent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1967982555</td>\n",
       "      <td>Fri May 29 20:33:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LMRB</td>\n",
       "      <td>@hma4983 It's the same house  We came back &amp;am...</td>\n",
       "      <td>[hma, hous, came, back, amp, outbid, buyer, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1967192097</td>\n",
       "      <td>Fri May 29 19:08:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gabeezy</td>\n",
       "      <td>@reginaislegit is the new david sides!!!  http...</td>\n",
       "      <td>[reginaislegit, new, david, side, p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1970340485</td>\n",
       "      <td>Sat May 30 03:27:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SharpShooter67</td>\n",
       "      <td>Driva! On the road again...</td>\n",
       "      <td>[driva, road]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  2012883900  Tue Jun 02 21:28:37 PDT 2009  NO_QUERY   \n",
       "1       0  2052369572  Sat Jun 06 00:30:08 PDT 2009  NO_QUERY   \n",
       "2       4  1967982555  Fri May 29 20:33:23 PDT 2009  NO_QUERY   \n",
       "3       4  1967192097  Fri May 29 19:08:12 PDT 2009  NO_QUERY   \n",
       "4       4  1970340485  Sat May 30 03:27:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  peterdarlington  @dubdotdash I don't have aircon  Lovely office...   \n",
       "1       Preetha_87  Yesterday wasn't a great day..my best friend's...   \n",
       "2             LMRB  @hma4983 It's the same house  We came back &am...   \n",
       "3          gabeezy  @reginaislegit is the new david sides!!!  http...   \n",
       "4   SharpShooter67                       Driva! On the road again...    \n",
       "\n",
       "                                      text_processed  \n",
       "0  [dubdotdash, aircon, love, offic, love, view, ...  \n",
       "1  [yesterday, great, day, best, friend, parent, ...  \n",
       "2  [hma, hous, came, back, amp, outbid, buyer, go...  \n",
       "3               [reginaislegit, new, david, side, p]  \n",
       "4                                      [driva, road]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Bag of Words\n",
    "words_lst = []\n",
    "\n",
    "for i in df['text_processed']:\n",
    "    words_lst += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dubdotdash', 'aircon', 'love', 'offic', 'love', 'view', 'veri', 'veri', 'chilli', 'yesterday', 'great', 'day', 'best', 'friend', 'parent', 'met', 'accid', 'thank', 'go', 'seriou', 'feel', 'freakin', 'bad', 'hma', 'hous', 'came', 'back', 'amp', 'outbid', 'buyer', 'go', 'ani', 'higher', 'though', 'bid', 'u', 'reginaislegit', 'new', 'david', 'side', 'p', 'driva', 'road', 'chrispenn', 'tweet', 'alert', 'keep', 'go', 'spam', 'box', 'time', 'pas', 'hurt', 'even', 'merz', 'soundcheck', 'parti', 'goer', 'get', 'one', 'mask', 'aheartofstar', 'damn', 'girl', 'fuck', 'suck', 'whi', 'aint', 'text', 'noth', 'hope', 'feel', 'better', 'way', 'way', 'way', 'alaska', 'mayn', 'new', 'moon', 'trailer', 'look', 'soooo', 'good', 'trinawright', 'well', 'yeah', 'hand', 'fuse', 'togeth', 'render', 'key', 'useless', 'key', 'liter', 'pocket', 'finish', 'veri', 'last', 'high']\n"
     ]
    }
   ],
   "source": [
    "# Sample of words list\n",
    "print(words_lst[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157531\n"
     ]
    }
   ],
   "source": [
    "# Lenght of words list\n",
    "print(len(words_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent words\n",
    "fdist = FreqDist(words_lst)\n",
    "\n",
    "top_5000 = fdist.most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('go', 1721),\n",
       " ('get', 1432),\n",
       " ('day', 1417),\n",
       " ('wa', 1264),\n",
       " ('thi', 1214),\n",
       " ('good', 1153),\n",
       " ('love', 1072),\n",
       " ('work', 1067),\n",
       " ('like', 1038),\n",
       " ('quot', 912)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of 5000 most frequent words\n",
    "top_5000[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-188-e2f66b7607fb>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feat['is_positive'] = feat['target'].apply(lambda x: True if x==4 else False)\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:4157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "<ipython-input-188-e2f66b7607fb>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feat[i] = feat['text_processed'].apply(lambda x: True if i in x else False)\n"
     ]
    }
   ],
   "source": [
    "# Building Features matrix\n",
    "col = [i[0] for i in top_5000]\n",
    "\n",
    "feat = df[['text_processed','target']]\n",
    "\n",
    "feat['is_positive'] = feat['target'].apply(lambda x: True if x==4 else False)\n",
    "\n",
    "feat.drop('target', axis=1, inplace=True)\n",
    "\n",
    "for i in col:\n",
    "    feat[i] = feat['text_processed'].apply(lambda x: True if i in x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>go</th>\n",
       "      <th>get</th>\n",
       "      <th>day</th>\n",
       "      <th>wa</th>\n",
       "      <th>thi</th>\n",
       "      <th>good</th>\n",
       "      <th>love</th>\n",
       "      <th>work</th>\n",
       "      <th>...</th>\n",
       "      <th>greec</th>\n",
       "      <th>rele</th>\n",
       "      <th>joejona</th>\n",
       "      <th>sixth</th>\n",
       "      <th>fate</th>\n",
       "      <th>xlc</th>\n",
       "      <th>borderlin</th>\n",
       "      <th>ufo</th>\n",
       "      <th>alexi</th>\n",
       "      <th>zabriel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dubdotdash, aircon, love, offic, love, view, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[yesterday, great, day, best, friend, parent, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hma, hous, came, back, amp, outbid, buyer, go...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[reginaislegit, new, david, side, p]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[driva, road]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  is_positive     go  \\\n",
       "0  [dubdotdash, aircon, love, offic, love, view, ...        False  False   \n",
       "1  [yesterday, great, day, best, friend, parent, ...        False   True   \n",
       "2  [hma, hous, came, back, amp, outbid, buyer, go...         True   True   \n",
       "3               [reginaislegit, new, david, side, p]         True  False   \n",
       "4                                      [driva, road]         True  False   \n",
       "\n",
       "     get    day     wa    thi   good   love   work  ...  greec   rele  \\\n",
       "0  False  False  False  False  False   True  False  ...  False  False   \n",
       "1  False   True  False  False  False  False  False  ...  False  False   \n",
       "2  False  False  False  False  False  False  False  ...  False  False   \n",
       "3  False  False  False  False  False  False  False  ...  False  False   \n",
       "4  False  False  False  False  False  False  False  ...  False  False   \n",
       "\n",
       "   joejona  sixth   fate    xlc  borderlin    ufo  alexi  zabriel  \n",
       "0    False  False  False  False      False  False  False    False  \n",
       "1    False  False  False  False      False  False  False    False  \n",
       "2    False  False  False  False      False  False  False    False  \n",
       "3    False  False  False  False      False  False  False    False  \n",
       "4    False  False  False  False      False  False  False    False  \n",
       "\n",
       "[5 rows x 5002 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features matrix\n",
    "feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features structure for nltk.NaiveBayesClassifier.train\n",
    "feature_lst = []\n",
    "\n",
    "for i in range(len(feat)):\n",
    "    is_pos = feat.loc[i,'is_positive']\n",
    "    dic = {}\n",
    "    for e in col:\n",
    "        dic[e] = feat.loc[i,e]\n",
    "    feature_lst.append((dic,is_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train and test sets\n",
    "train_set, test_set = feature_lst[:16000], feature_lst[-4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    sigh = True            False : True   =     22.8 : 1.0\n",
      "            followfriday = True             True : False  =     19.9 : 1.0\n",
      "                     thx = True             True : False  =     19.2 : 1.0\n",
      "                 congrat = True             True : False  =     16.2 : 1.0\n",
      "                     vip = True             True : False  =     16.0 : 1.0\n",
      "                     sad = True            False : True   =     15.1 : 1.0\n",
      "                   badli = True            False : True   =     11.9 : 1.0\n",
      "                  welcom = True             True : False  =     11.4 : 1.0\n",
      "                     bum = True            False : True   =     11.3 : 1.0\n",
      "                    grrr = True            False : True   =     10.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Most Informative Features\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731\n"
     ]
    }
   ],
   "source": [
    "# Testing Naive Bayes Model\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
